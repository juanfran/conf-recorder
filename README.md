## Requirements

- NVM or Node 22
- ffmpeg

## Optional

Needed if you are running whisper an the summary model locally

- [insanely-fast-whisper](https://github.com/Vaibhavs10/insanely-fast-whisper)
- [Ollama](https://ollama.com/)

## Installation

```bash
nvm install
pnpm install
ollama pull llama3.1:8b
```
